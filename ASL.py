import streamlit as st
import mediapipe as mp
import cv2
import numpy as np
from urllib.parse import urlparse, parse_qs
import pandas as pd
import tensorflow as tf
import random
import tempfile
import time
from PIL import Image, ImageTk
import random
import os
import time
import csv
import copy
import argparse
import itertools
from collections import Counter, deque
import speech_recognition as sr
import json
from time import strftime
from moviepy.editor import VideoFileClip
import subprocess

from text_to_speech import translate_to_vn, speak_from_text, translate_from_en

# Isolated ASL
from inference import inference_ASL, load_relevant_data_subset
from create_frame_parquet import create_output_parquet

# Fingerspelling ASL
from inference_fingerspelling import load_relevant_data_subset_fingerspelling
from create_parquet_fingerspelling import create_output_parquet_fingerspelling
from condition_dictionary import getValue, changeValue, createCsv



# Argument Parsers
def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--device", type=int, default=0)
    parser.add_argument("--width", help='cap width', type=int, default=960)
    parser.add_argument("--height", help='cap height', type=int, default=540)

    parser.add_argument('--use_static_image_mode', action='store_true')
    parser.add_argument("--min_detection_confidence",
                        help='min_detection_confidence',
                        type=float,
                        default=0.7)
    parser.add_argument("--min_tracking_confidence",
                        help='min_tracking_confidence',
                        type=int,
                        default=0.5)
                        
    args = parser.parse_args()

    return args
                    
args = get_args()

cap_device = args.device
cap_width = args.width
cap_height = args.height

use_static_image_mode = args.use_static_image_mode
min_detection_confidence = args.min_detection_confidence
min_tracking_confidence = args.min_tracking_confidence


# ----------------------Page config--------------------------------------

st.set_page_config(page_title="Sign Language Recognition", page_icon=":hand:", layout="wide")


st.markdown(
    """
    <style>
    [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
    }
    [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
        margin-left: -350px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)
def random_numbers_except_one(x, n, excluded):
    numbers = set()
    while len(numbers) < x:
        num = random.randint(0, n)
        if num != excluded:
            numbers.add(num)
    numbers.add(excluded)
    result = list(numbers)
    random.shuffle(result)  # S·∫Øp x·∫øp ng·∫´u nhi√™n danh s√°ch k·∫øt qu·∫£
    return result
# CSS styles
css = open("style.css")
st.markdown(f"<style>{css.read()}</style>", unsafe_allow_html=True)
css.close()

### Google - Isolated American Sign Language 
@st.cache_resource
def loading_model():
    interpreter = tf.lite.Interpreter(model_path="resources/model_weights/ISLR/model.tflite")
    found_signatures = list(interpreter.get_signature_list().keys())

    # if REQUIRED_SIGNATURE not in found_signatures:
    #     raise KernelEvalException('Required input signature not found.')

    prediction_fn = interpreter.get_signature_runner("serving_default")
    return prediction_fn

@st.cache_data
def loading_class():
    train = pd.read_csv('resources/data/ISLR/train.csv')
    train['sign_ord'] = train['sign'].astype('category').cat.codes

    # Dictionaries
    SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()
    ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()
    return ORD2SIGN
def get_question():
    sheet_id = "1dbaXMziDDIQ9Rbt7yoNQPWMSOw72iGs1HNAYwPiu7lU"
    sheet_name = "dictionary"
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}"
    df = pd.read_csv(url, dtype=str).fillna("")

    data = []
    for i in range (0, df['Links'].size):
        ans = random_numbers_except_one(3,df['Links'].size-1, i)
        
        data.append({
            'type':1,
            'url': df["Links"][int(i)],
            'correct_answer': df["Labels"][i],
            'A': df["Labels"][int(ans[0])],
            'B': df["Labels"][int(ans[1])],
            'C': df["Labels"][int(ans[2])],
            'D': df["Labels"][int(ans[3])]
        })
    # for i in range (0, df['Links'].size):
    #     ans = random_numbers_except_one(1,df['Links'].size-1, i)
        
    #     data.append({
    #         'type':0,
    #         'url': df["Links"][int(i)],
    #         'word': df["Labels"][i],
    #         'A': df["Links"][int(ans[0])],
    #         'B': df["Links"][int(ans[1])],

    #     })

    return random.sample(data, len(data))


def initialize_session_state():
    session_state = st.session_state
    session_state.form_count = 0
    session_state.quiz_data = get_question()
def loading_inference_video(video_path="videos/hello.mp4", prediction_fn = None, ORD2SIGN = None):
    if prediction_fn is None:
        prediction_fn = loading_model()
        
    # Create output parquet file
    create_output_parquet(video_path)

    # Predict from parquet file
    pq_file = "resources/data/ISLR/output.parquet"

    try:
        coordinates_xyz_np = load_relevant_data_subset(pq_file)
        prediction = prediction_fn(inputs=coordinates_xyz_np)
        sign = np.argmax(prediction['outputs'])
        return ORD2SIGN[sign]
        # print(sign)
        
    except:
        return "Video is invalid!!!"

### Loading model and class ISL
prediction_fn = loading_model()
ORD2SIGN = loading_class()


### Google - American Sign Language Fingerspelling Recognition
REQUIRED_OUTPUT = "outputs"

@st.cache_resource
def loading_model_fingerspelling():
    model_path = "resources/model_weights/ASL_Fingerspelling/model.tflite"

    interpreter = tf.lite.Interpreter(model_path)
    found_signatures = list(interpreter.get_signature_list().keys())

    # if REQUIRED_SIGNATURE not in found_signatures:
    #     raise KernelEvalException('Required input signature not found.')

    prediction_fn = interpreter.get_signature_runner("serving_default")
    
    return prediction_fn

@st.cache_data
def loading_charater_fingerspelling():
    with open ("resources/data/ASL_Fingerspelling/character_to_prediction_index.json", "r") as f:
        character_map = json.load(f)
    rev_character_map = {j:i for i,j in character_map.items()}
    return rev_character_map

@st.cache_data
def loading_fingerspelling_columns():
    with open('resources/data/ASL_Fingerspelling/inference_args.json', 'r') as file:
        data = json.load(file)

    SEL_COLS = data['selected_columns']
    return SEL_COLS

def loading_inference_video_fingerspelling(video_path="videos/fingerspelling/obrien.mp4", prediction_fn=None, rev_character_map=None):
    # Create output.parquet
    create_output_parquet_fingerspelling(video_path)
    
    try:
        rq_path = 'resources/data/ASL_Fingerspelling/output.parquet'
        frames = load_relevant_data_subset_fingerspelling(rq_path)
        # print(frames.dtypes)
        frames = frames.astype('float32')

        output = prediction_fn(inputs=frames)
        prediction_str = "".join([rev_character_map.get(s, "") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])
        return prediction_str
    except Exception as e:
        return "Video is invalid !!!"
    
# Function to record video
def record_video(filename, duration, frame_window):
    cap = cv2.VideoCapture(0)  # Start the webcam
    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Define the codec
    out = cv2.VideoWriter(filename, fourcc, 24.0, (640, 480))  # Create VideoWriter object

    start_time = time.time()

    while True:
        ret, frame = cap.read()  # Capture frame-by-frame
        if ret:
            out.write(frame)  # Write the frame into the file
            # cv2.imshow('Recording...', frame)  # Display the recording frame
            frame_window.image(frame, channels='BGR')
        if (time.time() - start_time) > duration:  # Check if duration is exceeded
            break
        # if cv2.waitKey(1) & 0xFF == ord('q'):  # Stop recording on 'q' key
        #     break

    cap.release()  # Release the capture
    out.release()  # Release the writer
    cv2.destroyAllWindows()  # Close all OpenCV windows

# Function to display a YouTube video within Streamlit
def show_video(link):
    st.video(link)

def run():
    st.session_state.run = True

### Loading model and class ASL Fingerspelling
prediction_fn_fingerspelling = loading_model_fingerspelling()
rev_character_map = loading_charater_fingerspelling()
SEL_COLS = loading_fingerspelling_columns()

### Page title
st.sidebar.title('Sign Language Recognition')

### App Mode
app_mode = st.sidebar.selectbox('Choose the App mode',
['About App','Isolated Sign Language Recognition', 'ASL Fingerspelling Recognition', 'Dictionary', 'Video Quiz', 'Action Checker']
)

if app_mode =='About App':
    st.title('‚úåü§ô‚úäSign Language Recognition')
    st.markdown(
    """
    <style>
    [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
    }
    [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
        margin-left: -350px;
    }
    </style>
    """,
    unsafe_allow_html=True,
    )
    st.markdown("Welcome to ASIGN, the American Sign Language Recognition and Inquiry Support Application :wave:.")
    st.markdown("ASIGN is an application designed to assist in recognizing and researching American Sign Language (ASL) :hand::call_me_hand::fist:.")
    st.markdown("Tailored to serve the deaf community and those interested in learning and understanding sign language, ASIGN offers a range of intelligent features and utilities suitable for both beginners and experienced sign language users.")
    st.markdown("ASIGN provides a powerful :zap: and user-friendly interactive experience :grin:. Here are the main features of the application:")
    st.markdown("1. Recognition of distinct sign languages from video :abc:: Users can upload videos, and the system will automatically analyze and provide a text description of the sign language used, helping users understand the information and meaning conveyed.")
    st.markdown("2. Spelling recognition using American Sign Language :capital_abcd:: Users can upload videos, and the system will automatically analyze and provide a text description of the finger-spelling in American Sign Language, aiding users in understanding how to express and use ASL.")
    st.markdown("3. Sign language word-by-word learning videos :notebook_with_decorative_cover:: ASIGN offers a diverse library of videos, with each word demonstrated by professional users, providing learners with the opportunity to observe and practice according to standard models.")
    st.markdown("4. Question and answer section :pencil:: To enhance the learning process, ASIGN offers a question and answer section, allowing users to test their knowledge and quickly access necessary information.")
    st.markdown("5. Analysis and practice from practice videos :film_projector:: This feature enables users to record and analyze themselves during sign language practice sessions, thereby improving their skills with confidence and effectiveness.")
    st.markdown("With the combination of advanced features and a user-friendly interface, ASIGN promises to provide users with an easy and effective learning experience and access to sign language :smiling_face_with_3_hearts:.")

elif app_mode == 'Isolated Sign Language Recognition':
    
    st.title(':call_me_hand: Isolated Sign Language Recognition from the video')
    st.markdown(
        """
        <style>
        [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
        }
        [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
            margin-left: -350px;
        }
        textarea {
        font-size: 2rem !important;
        }
        .stButton > button {
        display: block;
        margin: 0 auto;
    }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.set_option('deprecation.showfileUploaderEncoding', False)
    
    st.markdown("This mode allows uploading videos and getting the corresponding isolated sign language returned. Users can upload videos depicting sign language, and the system will then analyze and return the isolated sign language as text based on the content of the uploaded video. Let's try it :hugging_face: !!!")
    st.markdown("---")
    st.subheader('Upload a video')
    video_file_buffer = st.file_uploader("", type="mp4", key="ISL")

    if video_file_buffer is not None:
        # Check video length
        with open("videos/temp_video.mp4", "wb") as f:
            f.write(video_file_buffer.getbuffer())

        # Read the Mp4 file
        video_path = "videos/temp_video.mp4"
        video = VideoFileClip(video_path)
        duration = video.duration
        video.close()

        # X√≥a t·ªáp t·∫°m th·ªùi
        os.remove(video_path)

        if duration > 30:
            st.warning("Sorry, the video is too long (maximum 30 seconds).", icon="‚ö†Ô∏è")
        else:
            video_bytes = video_file_buffer.read()
            
            video_path_save = 'videos/video.mp4'
            
            with open(video_path_save, 'wb') as f:
                f.write(video_bytes)

            st.success("The video has been uploaded successfully.", icon="‚úÖ")
            
            st.video(video_path_save, loop=True)
            
            if st.button("Predict"):
                status_placeholder = st.empty()
                with status_placeholder:
                    st.write('<div style="text-align:center;">Processing...</div>', unsafe_allow_html=True)
                # predicted = inference_ASL(video_path_save)
                predicted = loading_inference_video(video_path_save, prediction_fn, ORD2SIGN)
                with status_placeholder:
                    status_placeholder.empty()
                
                # Print
                print(predicted)
                st.text_area(label="", value=predicted, height=50)
    
elif app_mode == 'ASL Fingerspelling Recognition':
    st.title(':v: American Sign Language Fingerspelling Recognition')
    st.markdown(
        """
        <style>
        [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
        }
        [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
            margin-left: -350px;
        }
        textarea {
            font-size: 2rem !important;
        }
        .stButton > button {
            display: block;
            margin: 0 auto;
        }
        .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
            font-size:1.1rem;
        }
        .font_des {
            font-size:15px !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.set_option('deprecation.showfileUploaderEncoding', False)
    
    upload_video, finger_data = st.tabs(["Upload a video", "ASL Fingerspelling"])
    
    with upload_video:
        st.markdown("")
        st.markdown("This mode allows uploading videos and getting the corresponding American sign language finger-spelling returned. Users can upload videos depicting sign language, and the system will then analyze and return the American sign language finger-spelling as text based on the content of the uploaded video. Enjoy :smile: !!!")
        st.markdown("---")
        st.subheader('Upload a video')
        
        video_file_buffer_fingerspelling = st.file_uploader("", type="mp4", key="FP")
        
        if video_file_buffer_fingerspelling is not None:
            # Check video length
            with open("videos/fingerspelling/temp_video.mp4", "wb") as f:
                f.write(video_file_buffer_fingerspelling.getbuffer())

            # Read the Mp4 file
            video_path = "videos/fingerspelling/temp_video.mp4"
            video = VideoFileClip(video_path)
            duration = video.duration
            video.close()

            # X√≥a t·ªáp t·∫°m th·ªùi
            os.remove(video_path)

            if duration > 60:
                st.warning("Sorry, the video is too long (maximum 60 seconds).", icon="‚ö†Ô∏è")
            else:
                video_bytes = video_file_buffer_fingerspelling.read()
                
                video_path_save_fingerspelling = 'videos/fingerspelling/video.mp4'
                
                with open(video_path_save_fingerspelling, 'wb') as f:
                    f.write(video_bytes)

                st.success("The video has been uploaded successfully.", icon="‚úÖ")
                
                st.video(video_path_save_fingerspelling, loop=True)
                
                if st.button("Predict"):
                    status_placeholder = st.empty()
                    with status_placeholder:
                        st.write('<div style="text-align:center;">Processing...</div>', unsafe_allow_html=True)

                    predicted = loading_inference_video_fingerspelling(video_path_save_fingerspelling, prediction_fn_fingerspelling, rev_character_map)
                    with status_placeholder:
                        status_placeholder.empty()
                    
                    # Print
                    print(predicted)
                    st.text_area(label="", value=predicted, height=50)
                    
    with finger_data: 
        st.markdown("")
        st.markdown('This image shows American Sign Language fingerspelling. The use of sign language is an important means of communication for deaf or hard of hearing people, helping them convey meaning and interact with the community around them.', unsafe_allow_html=True)
        st.markdown("")

        col1, col2, col3 = st.columns([0.6, 3.8, 0.6])
        col2.image('resources/data/ASL_Fingerspelling/ASL.png', caption='American Sign Language Fingerspelling', width = 300, use_column_width=True)

elif app_mode == 'Dictionary':
    st.title(":film_frames: Dictionary")
    st.markdown("This dictionary will contain videos of the corresponding sign language words :v::call_me_hand:	:sign_of_the_horns:.")
    st.markdown("Hopefully these videos will help you learn and use sign language better. :partying_face:")
    st.markdown("If there is a video, a button will appear corresponding to the word you searched for :mag_right:.")
    st.markdown(" And you just need to click on that button and the video will be displayed (:double_vertical_bar:). If there is no video, there will be a warning :warning:.")
    # Connect to the Google Sheet
    sheet_id = "1dbaXMziDDIQ9Rbt7yoNQPWMSOw72iGs1HNAYwPiu7lU"
    sheet_name = "dictionary"
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}"
    @st.cache_data
    def load_data():
        # Read data from Google Sheet
        df = pd.read_csv(url, dtype=str).fillna("")
        return df

    df = load_data()

    if 'stage' not in st.session_state:
        st.session_state.stage = 0
        createCsv()

    def set_stage(stage):
            st.session_state.stage = stage

    def clear_text():
        st.session_state.my_text = st.session_state.widget
        #print("Thay doi text_search")
        changeValue("Choose_label", "0")
        changeValue("Click", "0")
        changeValue("All", "0")
        changeValue("Search", "1")
        st.session_state.widget = ""

    text_search = st.text_input("Enter the word you want to search for in the search bar", value="", 
                key='widget', 
                on_change=clear_text
                ).lower()

    #print("Bat dau lai tu dau")

    text_search = st.session_state.get('my_text', '')


    if getValue("Search") == "0":
        text_search = ""
        
    #print("Text search is:", text_search)

    choose_label = getValue("Choose_label")
    #print("Choose label l√†:", choose_label)

    if choose_label == "0":
        #print("chay lai")
        print("")

    if choose_label != "0":
        text_search = choose_label
        #print("da chon")

    # Filter the dataframe based on search term
    m1 = df["Labels"].str.contains(text_search)
    df_search = df[m1]

    # Show warning if no matching results found
    if df_search.empty and text_search:
        st.warning("No matching results found for the search term.", icon="‚ö†Ô∏è")

    # Show the cards
    N_cards_per_row = 4

    #print("GetAll: ", getValue("All"))

    if not text_search or getValue("All") == "1":
        df_display = df
    else:
        df_display = df_search

    #print("B·∫Øt ƒë·∫ßu l·∫°i")
    #print("session stage:" ,st.session_state.stage)
    #print("Click:", getValue("Click"))

    if getValue("Click") == "0":
        st.markdown(
            """
            <style>
                /* Thi·∫øt k·∫ø l·∫°i giao di·ªán cho n√∫t button */
                div.stButton > button {
                    padding: 0.8em 2em;
                    font-size: 8px;
                    text-transform: uppercase;
                    letter-spacing: 2.5px;
                    font-weight: 300;
                    color: #000;
                    background-color: #fff;
                    border: 4 px solid grey;
                    border-radius: 45px;
                    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
                    transition: all 0.3s ease 0s;
                    cursor: pointer;
                    outline: none;
                    width: 180px; /* Ch·ªânh s·ª≠a chi·ªÅu r·ªông c·ªßa button ƒë·ªÉ c·ªë ƒë·ªãnh k√≠ch th∆∞·ªõc */
                }

                div.stButton > button:hover {
                    background-color: #23c483;
                    box-shadow: 0px 15px 20px rgba(46, 229, 157, 0.4);
                    color: #fff;
                    transform: translateY(-3px);
                }

                div.stButton > button:active {
                    transform: translateY(-1px);
                }
            </style>
            """,
            unsafe_allow_html=True
        )

        # D√πng v√≤ng l·∫∑p ƒë·ªÉ t·∫°o c√°c n√∫t button
        for n_row, row in df_display.reset_index().iterrows():
            i = n_row % N_cards_per_row
            if i == 0:
                st.write("---")
                cols = st.columns(N_cards_per_row, gap="large")
            # draw the card
            with cols[n_row % N_cards_per_row]:
                labels = row["Labels"].strip().split()
                for label in labels:
                    # S·ª≠ d·ª•ng st.markdown ƒë·ªÉ t·∫°o n√∫t button v√† √°p d·ª•ng CSS
                    if st.button(label):
                        #print("session stage:" ,st.session_state.stage)
                        #print(label)
                        changeValue("Choose_label", label)
                        changeValue("Click", "1")
                        changeValue("All", "0")
                        changeValue("Search", "0")
                        set_stage(1)
                        st.experimental_rerun()


    elif getValue("Click") == "1":
        #print("Da ch·ªçn 1 t·ª´")
        #print(getValue("Choose_label"))
        if st.button("Back", on_click=set_stage(2)):
            print("back l·∫°i ban ƒë·∫ßu") 
        video_links = df[df['Labels'].str.contains(getValue("Choose_label"))]['Links'].tolist()
        video_id = video_links[0].split('=')[1]
        # N·∫øu c√≥ th√™m tham s·ªë sau video_id, ti·∫øp t·ª•c t√°ch chu·ªói b·∫±ng '&' v√† l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
        if '&' in video_id:
            video_id = video_id.split('&')[0]

        # Hi·ªÉn th·ªã ti√™u ƒë·ªÅ v√† video ·ªü gi·ªØa m√†n h√¨nh
        st.markdown(
            f"""
            <div style="display: flex; flex-direction: column; align-items: center;">
                <p style="font-size: 45px; color: black; font-weight: bold;">{getValue("Choose_label")}</p>
                <iframe width="600" height="450" src="https://www.youtube.com/embed/{video_id}" frameborder="0" allowfullscreen></iframe>
            </div>
            """,
            unsafe_allow_html=True
        )

        # Ki·ªÉm tra v√† thay ƒë·ªïi stage n·∫øu c·∫ßn
        if st.session_state.stage == 2:
            changeValue("Choose_label", "0")
            changeValue("Click", "0")
            changeValue("All", "1")
            changeValue("Search", "0")   
            print("Da thay doi ca gia")
            set_stage(0)

elif app_mode == 'Video Quiz':
    st.title('Video Quiz')
    st.markdown("This quiz review feature allows users to revisit and reflect on their quiz questions and answers :pencil:")
    st.markdown("Please select the corresponding answer that is indicated in the clip, submit to see the results, and then continue with the next video to keep reviewing.")
    if 'form_count' not in st.session_state:
        initialize_session_state()
    if not st.session_state.quiz_data:
        st.session_state.quiz_data = get_question()
    if 'stage' not in st.session_state:
        st.session_state.stage = 0

    def set_stage(stage):
        st.session_state.stage = stage
        print( st.session_state.stage)

    quiz_data = st.session_state.quiz_data
            
    link = str(quiz_data[st.session_state.form_count]['url'])
    print(quiz_data)
    def get_video_id(url):
    # Ph√¢n t√≠ch URL
        parsed_url = urlparse(url)
        # Tr√≠ch xu·∫•t c√°c tham s·ªë t·ª´ URL
        query_params = parse_qs(parsed_url.query)
        # L·∫•y gi√° tr·ªã c·ªßa tham s·ªë 'v'
        video_id = query_params.get('v')
        
        # Tr·∫£ v·ªÅ gi√° tr·ªã video ID, n·∫øu t·ªìn t·∫°i
        if video_id:
            return video_id[0]
        return None
    print(get_video_id(link))
    
    st.markdown(
            f"""
            <div style="display: flex; flex-direction: column; align-items: center;">
                <iframe width="600" height="450" src="https://www.youtube.com/embed/{get_video_id(link)}?modestbranding=0&showinfo=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            """,
            unsafe_allow_html=True
        )

    user_answer = st.radio('What is your answer?', [quiz_data[st.session_state.form_count]['A'], quiz_data[st.session_state.form_count]['B'], quiz_data[st.session_state.form_count]['C'], quiz_data[st.session_state.form_count]['D']], on_change=set_stage, args=(0,))


    st.button('Check Answer', on_click=set_stage, args=(1,))
    if st.session_state.stage >0 :
        correct_answer = quiz_data[st.session_state.form_count]['correct_answer']
        if user_answer == correct_answer:
            st.success('Correct! The answer is {}'.format(correct_answer))
        else:
            st.error('Incorrect. The correct answer is {}'.format(correct_answer))
        another_question = st.button("Another question", on_click=set_stage, args=(2,))
    if st.session_state.stage >1 :
        st.session_state.form_count+=1
        set_stage(0)
        st.experimental_rerun()


elif app_mode == 'Action Checker':
    st.title("Action Checker")

    st.markdown("This mode is an extension of the Dictionary mode. It allows users to select a word from the dictionary, record a video of themselves and the system will check if the action of the user matches the selected word.")
    # st.markdown("")
    # Connect to the Google Sheet
    sheet_id = "1dbaXMziDDIQ9Rbt7yoNQPWMSOw72iGs1HNAYwPiu7lU"
    sheet_name = "dictionary"
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}"
    @st.cache_data
    def load_data():
        # Read data from Google Sheet
        df = pd.read_csv(url, dtype=str).fillna("")
        return df

    df = load_data()

    if 'stage' not in st.session_state:
        st.session_state.stage = 0
        createCsv()

    def set_stage(stage):
            st.session_state.stage = stage

    def clear_text():
        st.session_state.my_text = st.session_state.widget
        #print("Thay doi text_search")
        changeValue("Choose_label", "0")
        changeValue("Click", "0")
        changeValue("All", "0")
        changeValue("Search", "1")
        st.session_state.widget = ""

    text_search = st.text_input("Enter the word you want to search for in the search bar", value="", 
                key='widget', 
                on_change=clear_text
                ).lower()

    #print("Bat dau lai tu dau")

    text_search = st.session_state.get('my_text', '')


    if getValue("Search") == "0":
        text_search = ""
        
    #print("Text search is:", text_search)

    choose_label = getValue("Choose_label")
    #print("Choose label l√†:", choose_label)

    if choose_label == "0":
        #print("chay lai")
        print("")

    if choose_label != "0":
        text_search = choose_label
        #print("da chon")

    # Filter the dataframe based on search term
    m1 = df["Labels"].str.contains(text_search)
    df_search = df[m1]

    # Show warning if no matching results found
    if df_search.empty and text_search:
        st.warning("No matching results found for the search term.", icon="‚ö†Ô∏è")

    # Show the cards
    N_cards_per_row = 4

    #print("GetAll: ", getValue("All"))

    if not text_search or getValue("All") == "1":
        df_display = df
    else:
        df_display = df_search

    if getValue("Click") == "0":
        st.markdown(
            """
            <style>
                /* Thi·∫øt k·∫ø l·∫°i giao di·ªán cho n√∫t button */
                div.stButton > button {
                    padding: 0.8em 2em;
                    font-size: 8px;
                    text-transform: uppercase;
                    letter-spacing: 2.5px;
                    font-weight: 300;
                    color: #000;
                    background-color: #fff;
                    border: 4 px solid grey;
                    border-radius: 45px;
                    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
                    transition: all 0.3s ease 0s;
                    cursor: pointer;
                    outline: none;
                    width: 180px; /* Ch·ªânh s·ª≠a chi·ªÅu r·ªông c·ªßa button ƒë·ªÉ c·ªë ƒë·ªãnh k√≠ch th∆∞·ªõc */
                }

                div.stButton > button:hover {
                    background-color: #23c483;
                    box-shadow: 0px 15px 20px rgba(46, 229, 157, 0.4);
                    color: #fff;
                    transform: translateY(-3px);
                }

                div.stButton > button:active {
                    transform: translateY(-1px);
                }
            </style>
            """,
            unsafe_allow_html=True
        )

        # D√πng v√≤ng l·∫∑p ƒë·ªÉ t·∫°o c√°c n√∫t button
        for n_row, row in df_display.reset_index().iterrows():
            i = n_row % N_cards_per_row
            if i == 0:
                st.write("---")
                cols = st.columns(N_cards_per_row, gap="large")
            # draw the card
            with cols[n_row % N_cards_per_row]:
                labels = row["Labels"].strip().split()
                for label in labels:
                    # S·ª≠ d·ª•ng st.markdown ƒë·ªÉ t·∫°o n√∫t button v√† √°p d·ª•ng CSS
                    if st.button(label):
                        changeValue("Choose_label", label)
                        changeValue("Click", "1")
                        changeValue("All", "0")
                        changeValue("Search", "0")
                        set_stage(1)
                        st.rerun()


    elif getValue("Click") == "1":
        if st.button("Back"):
            set_stage(2)
            print("back l·∫°i ban ƒë·∫ßu") 
        st.markdown(f'<p style="font-size: 30px; color: black; font-weight: bold;">{getValue("Choose_label")}</p>', unsafe_allow_html=True)
        video_links = df[df['Labels'].str.contains(getValue("Choose_label"))]['Links'].tolist()
        video_id = video_links[0].split('=')[1]
        # N·∫øu c√≥ th√™m tham s·ªë sau video_id, ti·∫øp t·ª•c t√°ch chu·ªói b·∫±ng '&' v√† l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
        if '&' in video_id:
            video_id = video_id.split('&')[0]
        #print(video_id)
        st.write(f'<iframe width="450" height="350" src="https://www.youtube.com/embed/{video_id}" frameborder="0" allowfullscreen></iframe>', unsafe_allow_html=True)

        FRAME_WINDOW = st.image([])

        if 'run' not in st.session_state:
            st.session_state.run = False

        st.button('Record Video', key='record_button', on_click=run, disabled=st.session_state.run)

        if st.session_state.run:
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.avi')
            record_video(tfile.name, 8, FRAME_WINDOW)

            FRAME_WINDOW.empty()

            st.success('Recording finished!')

            # Convert XVID to H.264 (MP4)
            mp4_filename = tfile.name.replace('.avi', '.mp4')
            subprocess.run(['ffmpeg', '-i', tfile.name, '-vcodec', 'libx264', mp4_filename])

            if os.path.exists(mp4_filename):
                st.video(mp4_filename, format='video/mp4', start_time=0)
                
            status_placeholder = st.empty()
            with status_placeholder:
                st.write('<div style="text-align:center;">Processing...</div>', unsafe_allow_html=True)
            predicted = loading_inference_video(mp4_filename, prediction_fn, ORD2SIGN)
            with status_placeholder:
                status_placeholder.empty()
        
            # Print
            print(predicted)
            st.text_area(label="Prediction", value=predicted, height=50)
            print(getValue("Choose_label"))
            if getValue("Choose_label") == predicted:
                st.success('Correct! Your action matches the selected word.')
            else:
                st.error('Incorrect. Your action does not match the selected word. Please try again.')
            st.session_state.run = False
            st.session_state.stop_recording = False

            if st.button("Rerun", key="rerun"):
                st.rerun()

        if st.session_state.stage == 2:
            changeValue("Choose_label", "0")
            changeValue("Click", "0")
            changeValue("All", "1")
            changeValue("Search", "0")   
            set_stage(0)
            st.rerun()